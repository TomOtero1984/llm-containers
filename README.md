# ðŸ”§ llm-containers

## Overview

llm-containers seeks to create a minimal containerized environment for hosting tiny llm models.

## Status

Successfully containerized Ollama in Ubuntu.

## Next Steps

Create custom Buildroot kernel with the bare minimum components needed to run a container engine (likely podman).
